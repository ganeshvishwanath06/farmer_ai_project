# algofarm.py - The final, hackathon-ready version
import streamlit as st
import openai
from gtts import gTTS
from deep_translator import GoogleTranslator
from PIL import Image
import torch
import torchvision.transforms as transforms
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights
import io
import os
import json
from datetime import datetime
import requests # Added back requests for the final code
import pydub # We still need pydub to handle the audio file conversion for gTTS

# --- Page Configuration ---
st.set_page_config(
    page_title="AI Farmer's Assistant üë®‚Äçüåæ",
    page_icon="üåø",
    layout="wide"
)

# --- App Title and Description ---
st.title("AI-Based Farmer Query Support and Advisory System üë®‚Äçüåæ")
st.markdown("Your digital Krishi Officer, ready to help with pests, weather, and market advice.")

# --- API Key Setup ---
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
except Exception as e:
    st.error("OpenAI API key not found. Please create a file at .streamlit/secrets.toml and add your key.", icon="üö®")
    st.stop()

# --- Session State Initialization ---
if 'language' not in st.session_state:
    st.session_state.language = 'ml' # Default to Malayalam
if 'location' not in st.session_state:
    st.session_state.location = ''
if 'crop' not in st.session_state:
    st.session_state.crop = ''
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'last_query' not in st.session_state:
    st.session_state.last_query = ""

# --- Disease Model Setup ---
# Note: For the hackathon, you can keep the fallback to ImageNet if you don't have a custom model.
# Option A: Provide a custom model and classes here.
MODEL_PATH = 'plant_disease_model.pth' # Make sure this file is in the same directory
DISEASE_CLASSES = [
    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 
    'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 
    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 
    'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 
    'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 
    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 
    'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 
    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 
    'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 
    'Tomato___Tomato_mosaic_virus', 'Tomato___healthy' 
]

@st.cache_resource
def load_model(model_path):
    try:
        if not os.path.exists(model_path):
            st.warning("Custom disease model not found. Using a generic pre-trained ImageNet model as a fallback.", icon="‚ö†Ô∏è")
            model = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)
            model.eval()
            return model, False
        
        model = mobilenet_v2(num_classes=len(DISEASE_CLASSES))
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
        model.eval()
        st.success("Plant disease model loaded successfully!", icon="‚úÖ")
        return model, True
    except Exception as e:
        st.error(f"Error loading model: {e}. Please ensure 'plant_disease_model.pth' is correct.", icon="üö®")
        return None, False

disease_model, is_custom_model_loaded = load_model(MODEL_PATH)

transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# --- Helper Functions ---
def get_season(month):
    """Simple function to get the season based on the month (for Indian context)"""
    if month in [3, 4, 5]:
        return "Summer"
    elif month in [6, 7, 8, 9]:
        return "Monsoon"
    elif month in [10, 11, 12]:
        return "Post-monsoon"
    else:
        return "Winter"

def translate_text(text, target_lang):
    if target_lang == 'en' or not text: return text
    try: return GoogleTranslator(source='auto', target=target_lang).translate(text)
    except Exception: return text

def text_to_speech(text, lang):
    try:
        tts = gTTS(text=text, lang=lang, slow=False)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        return fp
    except Exception: return None

def log_query(query, response, context, feedback=None):
    """Logs the user query and AI response for the 'learning loop' and 'escalation'."""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "query": query,
        "response": response,
        "context": context,
        "feedback": feedback
    }
    with open("query_logs.jsonl", "a") as f:
        json.dump(log_entry, f)
        f.write('\n')

def get_llm_response(query, context):
    try:
        # This is the core of the context-aware system
        prompt = f"""
        You are an expert AI agricultural assistant for farmers in India.
        Your answers must be simple, practical, and in the same language as the user's query.
        Be concise and direct in your advice.
        Current Context:
        - Farmer's Location: {context.get('location', 'Not provided')}
        - Current Crop: {context.get('crop', 'Not provided')}
        - Language of Query: {context.get('language_name', 'English')}
        - Current Season: {context.get('season', 'Not provided')}
        User's Question: "{query}"
        Provide a helpful and actionable response.
        """
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": query}
            ],
            max_tokens=300,
            temperature=0.7,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"Error getting response from AI model: {e}")
        return "Sorry, I couldn't process your request at the moment. Please try again."

def predict_disease(image_bytes):
    if not disease_model: return "Model not loaded.", 0.0
    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        outputs = disease_model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
        top_prob, top_catid = torch.max(probabilities, 0)
    
    if is_custom_model_loaded and top_catid.item() < len(DISEASE_CLASSES):
        class_name = DISEASE_CLASSES[top_catid.item()]
    else:
        # Fallback for generic model
        generic_classes = ['Fungal infection', 'Bacterial issue', 'Nutrient deficiency', 'Healthy']
        class_name = generic_classes[top_catid.item() % len(generic_classes)]
    return class_name.replace("_", " "), top_prob.item()

# --- Pre-defined Data for Schemes (Simulating a local database) ---
SCHEMES_DATA = {
    "en": {
        "PM-KISAN Scheme": "Provides income support of Rs. 6,000 per year to all landholding farmer families.",
        "Pradhan Mantri Fasal Bima Yojana (PMFBY)": "An insurance service for crop losses due to natural calamities, pests, and diseases.",
        "Kisan Credit Card (KCC)": "Provides timely credit support to farmers for their cultivation and other needs.",
        "Soil Health Card Scheme": "Promotes soil testing and provides a report card to help farmers apply nutrients as per crop needs.",
    },
    "ml": {
        "‡¥™‡¥ø‡¥é‡¥Ç-‡¥ï‡¥ø‡¥∏‡¥æ‡µª ‡¥™‡¥¶‡µç‡¥ß‡¥§‡¥ø": "‡¥é‡¥≤‡µç‡¥≤‡¥æ ‡¥≠‡µÇ‡¥µ‡µÅ‡¥ü‡¥Æ‡¥ï‡¥≥‡¥æ‡¥Ø ‡¥ï‡µº‡¥∑‡¥ï ‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µÅ‡¥Ç ‡¥™‡µç‡¥∞‡¥§‡¥ø‡¥µ‡µº‡¥∑‡¥Ç 6,000 ‡¥∞‡µÇ‡¥™ ‡¥µ‡¥∞‡µÅ‡¥Æ‡¥æ‡¥® ‡¥∏‡¥π‡¥æ‡¥Ø‡¥Ç ‡¥®‡µΩ‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.",
        "‡¥™‡µç‡¥∞‡¥ß‡¥æ‡¥®‡¥Æ‡¥®‡µç‡¥§‡µç‡¥∞‡¥ø ‡¥´‡¥∏‡µΩ ‡¥¨‡µÄ‡¥Æ ‡¥Ø‡µã‡¥ú‡¥® (‡¥™‡¥ø‡¥é‡¥Ç‡¥é‡¥´‡µç‡¥¨‡¥ø‡¥µ‡µà)": "‡¥™‡µç‡¥∞‡¥ï‡µÉ‡¥§‡¥ø ‡¥¶‡µÅ‡¥∞‡¥®‡µç‡¥§‡¥ô‡µç‡¥ô‡µæ, ‡¥ï‡µÄ‡¥ü‡¥ô‡µç‡¥ô‡µæ, ‡¥∞‡µã‡¥ó‡¥ô‡µç‡¥ô‡µæ ‡¥é‡¥®‡µç‡¥®‡¥ø‡¥µ ‡¥ï‡¥æ‡¥∞‡¥£‡¥Ç ‡¥µ‡¥ø‡¥≥‡¥®‡¥æ‡¥∂‡¥Ç ‡¥∏‡¥Ç‡¥≠‡¥µ‡¥ø‡¥ö‡µç‡¥ö‡¥æ‡µΩ ‡¥á‡µª‡¥∑‡µÅ‡¥±‡µª‡¥∏‡µç ‡¥™‡¥∞‡¥ø‡¥∞‡¥ï‡µç‡¥∑ ‡¥®‡µΩ‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.",
        "‡¥ï‡¥ø‡¥∏‡¥æ‡µª ‡¥ï‡µç‡¥∞‡µÜ‡¥°‡¥ø‡¥±‡µç‡¥±‡µç ‡¥ï‡¥æ‡µº‡¥°‡µç (‡¥ï‡µÜ‡¥∏‡¥ø‡¥∏‡¥ø)": "‡¥ï‡µº‡¥∑‡¥ï‡µº‡¥ï‡µç‡¥ï‡µç ‡¥Ö‡¥µ‡¥∞‡µÅ‡¥ü‡µÜ ‡¥ï‡µÉ‡¥∑‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥Ç ‡¥Æ‡¥±‡µç‡¥±‡µç ‡¥Ü‡¥µ‡¥∂‡µç‡¥Ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µÅ‡¥Ç ‡¥∏‡¥Æ‡¥Ø‡¥¨‡¥®‡µç‡¥ß‡¥ø‡¥§‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥µ‡¥æ‡¥Ø‡µç‡¥™‡¥æ ‡¥∏‡¥π‡¥æ‡¥Ø‡¥Ç ‡¥®‡µΩ‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.",
        "‡¥Æ‡¥£‡µç‡¥£‡µç ‡¥Ü‡¥∞‡µã‡¥ó‡µç‡¥Ø ‡¥ï‡¥æ‡µº‡¥°‡µç ‡¥™‡¥¶‡µç‡¥ß‡¥§‡¥ø": "‡¥Æ‡¥£‡µç‡¥£‡µç ‡¥™‡¥∞‡¥ø‡¥∂‡µã‡¥ß‡¥® ‡¥™‡µç‡¥∞‡µã‡¥§‡µç‡¥∏‡¥æ‡¥π‡¥ø‡¥™‡µç‡¥™‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï‡¥Ø‡µÅ‡¥Ç ‡¥µ‡¥ø‡¥≥‡¥ï‡¥≥‡µÅ‡¥ü‡µÜ ‡¥Ü‡¥µ‡¥∂‡µç‡¥Ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡¥®‡µÅ‡¥∏‡¥∞‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥™‡µã‡¥∑‡¥ï‡¥ô‡µç‡¥ô‡µæ ‡¥™‡µç‡¥∞‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥ï‡µº‡¥∑‡¥ï‡¥∞‡µÜ ‡¥∏‡¥π‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥® ‡¥±‡¥ø‡¥™‡µç‡¥™‡µã‡µº‡¥ü‡µç‡¥ü‡µç ‡¥ï‡¥æ‡µº‡¥°‡µç ‡¥®‡µΩ‡¥ï‡µÅ‡¥ï‡¥Ø‡µÅ‡¥Ç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡µÅ.",
    },
    "hi": {
        "‡§™‡•Ä‡§è‡§Æ-‡§ï‡§ø‡§∏‡§æ‡§® ‡§Ø‡•ã‡§ú‡§®‡§æ": "‡§∏‡§≠‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ß‡§æ‡§∞‡§ï ‡§ï‡§ø‡§∏‡§æ‡§® ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø ‡§µ‡§∞‡•ç‡§∑ 6,000 ‡§∞‡•Å‡§™‡§Ø‡•á ‡§ï‡•Ä ‡§Ü‡§Ø ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§",
        "‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§¨‡•Ä‡§Æ‡§æ ‡§Ø‡•ã‡§ú‡§®‡§æ (‡§™‡•Ä‡§è‡§Æ‡§è‡§´‡§¨‡•Ä‡§µ‡§æ‡§à)": "‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§Ü‡§™‡§¶‡§æ‡§ì‡§Ç, ‡§ï‡•Ä‡§ü‡•ã‡§Ç ‡§î‡§∞ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§´‡§∏‡§≤ ‡§ï‡•á ‡§®‡•Å‡§ï‡§∏‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§¨‡•Ä‡§Æ‡§æ ‡§∏‡•á‡§µ‡§æ‡•§",
        "‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•ç‡§∞‡•á‡§°‡§ø‡§ü ‡§ï‡§æ‡§∞‡•ç‡§° (‡§ï‡•á‡§∏‡•Ä‡§∏‡•Ä)": "‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§â‡§®‡§ï‡•Ä ‡§ñ‡•á‡§§‡•Ä ‡§î‡§∞ ‡§Ö‡§®‡•ç‡§Ø ‡§ú‡§∞‡•Ç‡§∞‡§§‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§Æ‡§Ø ‡§™‡§∞ ‡§ã‡§£ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§",
        "‡§Æ‡•É‡§¶‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§ï‡§æ‡§∞‡•ç‡§° ‡§Ø‡•ã‡§ú‡§®‡§æ": "‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§¶‡•á‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§ú‡§∞‡•Ç‡§∞‡§§‡•ã‡§Ç ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§™‡•ã‡§∑‡§ï ‡§§‡§§‡•ç‡§µ‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§æ‡§∞‡•ç‡§° ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§",
    }
}

# --- Sidebar ---
with st.sidebar:
    st.header("Settings ‚öôÔ∏è")
    lang_map = {'ml': '‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç', 'en': 'English', 'hi': '‡§π‡§ø‡§®‡•ç‡§¶‡•Ä'}
    lang_code_map = {'ml': 'ml-IN', 'en': 'en-US', 'hi': 'hi-IN'}
    selected_lang = st.selectbox("Choose your language:", options=list(lang_map.keys()), format_func=lambda x: lang_map[x])
    st.session_state.language = selected_lang

    st.text_input("üìç Your Location (e.g., Alappuzha, Kerala)", key='location')
    st.text_input("üåæ Your Primary Crop (e.g., Banana, Rice)", key='crop')

    st.markdown("---")
    app_mode = st.radio("Choose a feature:", ("‚ùì Ask a Question", "üì∏ Photo Diagnosis", "üì¢ Government Schemes"))

# --- Main App Logic ---
if app_mode == "‚ùì Ask a Question":
    st.header("Ask a Question in Your Language")
    
    uploaded_audio = st.file_uploader("Upload an audio file to transcribe (MP3, WAV, M4A)", type=["mp3", "wav", "m4a"])
    user_query = ""

    if uploaded_audio:
        st.audio(uploaded_audio)
        st.info("Transcribing audio...")
        with st.spinner("Transcribing..."):
            try:
                transcript = openai.audio.transcriptions.create(
                    model="whisper-1",
                    file=uploaded_audio,
                    language=st.session_state.language
                )
                user_query = transcript.text
                st.success("Transcription complete.")
            except openai.APIError as e:
                st.error(f"Error with OpenAI's API: {e}")
                user_query = ""
            except Exception as e:
                st.error(f"An unexpected error occurred: {e}")
                user_query = ""
    
    # Text input for manual query
    text_query = st.text_input("Or type your question here:", key="query_input")
    
    if text_query:
        user_query = text_query

    if user_query:
        st.markdown(f"**Your Question:** *{user_query}*")
        with st.spinner("Thinking... ü§ñ"):
            translated_query_for_llm = translate_text(user_query, 'en')
            context = {
                'location': st.session_state.location,
                'crop': st.session_state.crop,
                'language_name': lang_map[st.session_state.language],
                'season': get_season(datetime.now().month)
            }
            llm_response_en = get_llm_response(translated_query_for_llm, context)
            final_response = translate_text(llm_response_en, st.session_state.language)
            st.markdown("---")
            st.subheader("üí° My Advice for You")
            st.markdown(final_response)
            
            # Add escalation and feedback logic
            if "sorry" in final_response.lower() or "couldn't" in final_response.lower() or "I cannot provide" in final_response.lower():
                st.info("Your query is complex. We've logged it for our agricultural experts to review. Thank you for your patience.")
                log_query(user_query, final_response, context, "Escalated")
            else:
                st.subheader("Was this helpful? (Learning Loop)")
                col_fb1, col_fb2 = st.columns([1, 10])
                with col_fb1:
                    if st.button("üëç"):
                        log_query(user_query, final_response, context, "Helpful")
                        st.success("Thank you for your feedback!")
                with col_fb2:
                    if st.button("üëé"):
                        log_query(user_query, final_response, context, "Not Helpful")
                        st.error("Thank you for your feedback. We will use this to improve.")
            
            audio_file = text_to_speech(final_response, st.session_state.language)
            if audio_file: st.audio(audio_file, format='audio/mp3')

elif app_mode == "üì∏ Photo Diagnosis":
    st.header("Upload a Photo of the Diseased Plant")
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)
        with st.spinner("Analyzing the image... üî¨"):
            disease_name, confidence = predict_disease(uploaded_file.getvalue())
            st.success(f"**Diagnosis:** {disease_name} (Confidence: {confidence:.2%})")
            st.subheader("ü§ñ Recommended Actions")
            context = {
                'location': st.session_state.location,
                'crop': st.session_state.crop,
                'language_name': lang_map[st.session_state.language],
                'season': get_season(datetime.now().month)
            }
            query_for_llm = f"My plant has been diagnosed with '{disease_name}'. What are the prevention, organic, and chemical control methods?"
            llm_response_en = get_llm_response(query_for_llm, context)
            final_response = translate_text(llm_response_en, st.session_state.language)
            st.markdown(final_response)
            audio_file = text_to_speech(final_response, st.session_state.language)
            if audio_file: st.audio(audio_file, format='audio/mp3')

elif app_mode == "üì¢ Government Schemes":
    st.header("Relevant Government Schemes for Farmers")
    schemes_lang = SCHEMES_DATA.get(st.session_state.language, SCHEMES_DATA['en'])
    for scheme, description in schemes_lang.items():
        with st.expander(f"**{scheme}**"):
            st.write(description)
            # Add audio playback for scheme description
            audio_file = text_to_speech(description, st.session_state.language)
            if audio_file: st.audio(audio_file, format='audio/mp3')